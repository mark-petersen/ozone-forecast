{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done importing libraries\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "\n",
    "## importing libraries\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics\n",
    "import math\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "print('Done importing libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7320 entries, 0 to 7319\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   a            7320 non-null   int64  \n",
      " 1   City         7320 non-null   object \n",
      " 2   Date         7320 non-null   object \n",
      " 3   Time         7320 non-null   object \n",
      " 4   PM2.5        7320 non-null   float64\n",
      " 5   PM10         7320 non-null   float64\n",
      " 6   NO           7320 non-null   float64\n",
      " 7   NO2          7320 non-null   float64\n",
      " 8   NOx          7320 non-null   float64\n",
      " 9   NH3          7320 non-null   float64\n",
      " 10  CO           7320 non-null   float64\n",
      " 11  SO2          7320 non-null   float64\n",
      " 12  O3           7320 non-null   float64\n",
      " 13  Benzene      7320 non-null   float64\n",
      " 14  Toluene      7320 non-null   float64\n",
      " 15  Xylene       7320 non-null   float64\n",
      " 16  O3P24        7320 non-null   float64\n",
      " 17  Temperature  7320 non-null   float64\n",
      "dtypes: float64(14), int64(1), object(3)\n",
      "memory usage: 1.0+ MB\n",
      "Index(['a', 'City', 'Date', 'Time', 'PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3',\n",
      "       'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'Xylene', 'O3P24',\n",
      "       'Temperature'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('Data/allFall_delhi.csv')\n",
    "df2.rename({\"Unnamed: 0\":\"a\"}, axis=\"columns\", inplace=True)\n",
    "df2.drop([\"index\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "Ozone = df2['O3']\n",
    "\n",
    "OzoneP24 = Ozone.shift(-24)\n",
    "OzoneP24 = OzoneP24.replace(np.nan, 54.94)\n",
    "df2['O3P24'] = OzoneP24\n",
    "\n",
    "df2.info()\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: 6588 rows\n",
      "Size of testing dataset: 732 rows\n",
      "Done defining variables\n"
     ]
    }
   ],
   "source": [
    "## defining variables\n",
    "\n",
    "#X = df2[['PM10', 'NO', 'NO2', 'CO', 'SO2', 'O3', 'Toluene', 'Temp']] # , 'Humid', Xylene\n",
    "X = df2[['PM10', 'NO', 'NO2', 'NH3','CO', 'SO2', 'O3', 'Toluene', 'Xylene', 'Temperature']]\n",
    "\n",
    "y = df2['O3P24']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train, y_test = train_test_split(X,y,random_state=0, test_size=0.1)\n",
    "\n",
    "print(\"Size of training dataset: {} rows\".format(X_train1.shape[0]))\n",
    "print(\"Size of testing dataset: {} rows\".format(X_test1.shape[0]))\n",
    "\n",
    "print('Done defining variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done scaling :)\n"
     ]
    }
   ],
   "source": [
    "## scaling variables\n",
    "\n",
    "'''importing libraries'''\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = preprocessing.RobustScaler()\n",
    "X_train_scaled1 = scaler.fit_transform(X_train1)\n",
    "X_test_scaled1 = scaler.fit_transform(X_test1)\n",
    "\n",
    "print('Done scaling :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32026539 0.28527367 0.49956145 0.46885147 0.33368824 0.40061604\n",
      " 0.47884701 0.3490707  0.33856104 0.37221278]\n",
      "[-33.13575608 -36.49598079 -30.83252573 -29.75087474 -30.99669513\n",
      " -31.24351898 -31.77566834 -37.07519601 -34.25850498 -32.45071191]\n",
      "[-20.80310253 -21.22417279 -20.28516262 -20.41383187 -20.99601429\n",
      " -19.83259719 -19.74967884 -21.87471065 -20.95413234 -19.83221266]\n",
      "0.3847 0.3838 32.8 20.6\n",
      "done training linear regressor | time taken: 0.392385 seconds\n",
      "The average R2 value for linear regressor is : 0.3847\n"
     ]
    }
   ],
   "source": [
    "## linear regression\n",
    "t0 = time.time()\n",
    "\n",
    "'''importing library'''\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "'''create linear regressor object'''\n",
    "lnRegressor = LinearRegression()\n",
    "\n",
    "'''fitting regressor'''\n",
    "lnRegressor.fit(X_train1, y_train)\n",
    "\n",
    "# cv stuff\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "cvln_r2scores = cross_val_score(lnRegressor, X_train1, y_train, cv = 10, scoring = 'r2')\n",
    "print(cvln_r2scores)\n",
    "cvln_rmsescores = cross_val_score(lnRegressor, X_train1, y_train, cv = 10, scoring = 'neg_root_mean_squared_error')\n",
    "print(cvln_rmsescores)\n",
    "cvln_maescores = cross_val_score(lnRegressor, X_train1, y_train, cv = 10, scoring = 'neg_mean_absolute_error')\n",
    "print(cvln_maescores)\n",
    "\n",
    "# calculating r^2 adj score\n",
    "\n",
    "cvln_adj = []\n",
    "\n",
    "n = len(X_train1)\n",
    "k = len(X_train1.columns)\n",
    "for r in cvln_r2scores:\n",
    "    adj_r2 = 1-(((1-r)*(n-1))/(n-k-1))\n",
    "    cvln_adj.append(adj_r2)    \n",
    "\n",
    "cvln_r2score = round((np.mean(cvln_r2scores)), 4)\n",
    "cvln_adjscore = round((np.mean(cvln_adj)), 4)\n",
    "cvln_rmsescore = (round(abs(np.mean(cvln_rmsescores)),2))\n",
    "cvln_maescore = (round(abs(np.mean(cvln_maescores)),2))\n",
    "\n",
    "\n",
    "print(cvln_r2score, cvln_adjscore, cvln_rmsescore, cvln_maescore)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "\n",
    "print(\"done training linear regressor | time taken: %f seconds\" %total)\n",
    "yPredln = lnRegressor.predict(X_test1)\n",
    "print('The average R2 value for linear regressor is :', cvln_r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING: KN\n",
      "[0.46407564 0.62066274 0.65991734 0.55472344 0.39121916 0.67157376\n",
      " 0.58331671 0.67151124 0.64444122 0.6278565 ]\n",
      "[-29.42245738 -26.58813661 -25.41709841 -27.23997229 -29.62832773\n",
      " -23.12737304 -28.412871   -26.33763671 -25.11766279 -24.98464672]\n",
      "[-16.80531013 -16.19481411 -14.93703208 -16.3475852  -16.56856539\n",
      " -14.77811898 -15.59477114 -15.8037747  -15.53974301 -14.42270281]\n",
      "0.5889 0.5883 26.63 15.7\n",
      "done training knn regressor | time taken: 2.019506 seconds\n",
      "The average R2 value for KNN Regressor is : 0.3847\n"
     ]
    }
   ],
   "source": [
    "## kneighbors regression\n",
    "print(\"STARTING: KN\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "'''importing library'''\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "'''create regressor object'''\n",
    "knRegressor = KNeighborsRegressor(n_neighbors = 4, metric = 'minkowski', p = 1)\n",
    "\n",
    "'''fitting regressor'''\n",
    "knRegressor.fit(X_train_scaled1, y_train)\n",
    "\n",
    "# cv stuff\n",
    "\n",
    "cvkn_r2scores = cross_val_score(knRegressor, X_train1, y_train, cv = 10, scoring = 'r2')\n",
    "print(cvkn_r2scores)\n",
    "cvkn_rmsescores = cross_val_score(knRegressor, X_train1, y_train, cv = 10, scoring = 'neg_root_mean_squared_error')\n",
    "print(cvkn_rmsescores)\n",
    "cvkn_maescores = cross_val_score(knRegressor, X_train1, y_train, cv = 10, scoring = 'neg_mean_absolute_error')\n",
    "print(cvkn_maescores)\n",
    "\n",
    "# calculating r^2 adj score\n",
    "\n",
    "cvkn_adj = []\n",
    "\n",
    "n = len(X_train1)\n",
    "k = len(X_train1.columns)\n",
    "for r in cvkn_r2scores:\n",
    "    adj_r2 = 1-(((1-r)*(n-1))/(n-k-1))\n",
    "    cvkn_adj.append(adj_r2)    \n",
    "\n",
    "cvkn_r2score = round((np.mean(cvkn_r2scores)), 4)\n",
    "cvkn_adjscore = round((np.mean(cvkn_adj)), 4)\n",
    "cvkn_rmsescore = (round(abs(np.mean(cvkn_rmsescores)),2))\n",
    "cvkn_maescore = (round(abs(np.mean(cvkn_maescores)),2))\n",
    "\n",
    "print(cvkn_r2score, cvkn_adjscore, cvkn_rmsescore, cvkn_maescore)\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "\n",
    "print(\"done training knn regressor | time taken: %f seconds\" %total)\n",
    "\n",
    "yPredkn = knRegressor.predict(X_test_scaled1)\n",
    "print('The average R2 value for KNN Regressor is :', cvln_r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING: SVR\n",
      "[0.42431359 0.37172612 0.49439835 0.45765963 0.51091743 0.43789555\n",
      " 0.41525857 0.41274261 0.42916908 0.47301932]\n",
      "[-41.2117769  -44.06144826 -45.44846251 -41.52536143 -39.1982607\n",
      " -41.47946456 -45.60051466 -47.38909043 -42.9924516  -41.80088174]\n",
      "[-29.32309723 -29.88109571 -33.16947386 -30.95463449 -30.50863809\n",
      " -30.13864559 -31.60834233 -32.00647415 -30.32783202 -30.50880739]\n",
      "0.4427 0.4419 43.07 30.84\n",
      "done training svr regressor | time taken: 262.592602 seconds\n",
      "The average R2 value for SVR Regressor is : 0.4427\n"
     ]
    }
   ],
   "source": [
    "## svr regressor\n",
    "print(\"STARTING: SVR\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "'''importing library'''\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "'''create regressor object'''\n",
    "svrRegressor = SVR(C = 10, gamma = 0.1, kernel= 'rbf')\n",
    "\n",
    "'''fitting regressor'''\n",
    "svrRegressor.fit(X_train_scaled1, y_train)\n",
    "\n",
    "# cv stuff\n",
    "\n",
    "cvsvr_r2scores = cross_val_score(svrRegressor, X_train_scaled1, y_train, cv = 10, scoring = 'r2')\n",
    "print(cvsvr_r2scores)\n",
    "cvsvr_rmsescores = cross_val_score(svrRegressor, X_train1, y_train, cv = 10, scoring = 'neg_root_mean_squared_error')\n",
    "print(cvsvr_rmsescores)\n",
    "cvsvr_maescores = cross_val_score(svrRegressor, X_train1, y_train, cv = 10, scoring = 'neg_mean_absolute_error')\n",
    "print(cvsvr_maescores)\n",
    "\n",
    "\n",
    "# calculating r^2 adj score\n",
    "\n",
    "cvsvr_adj = []\n",
    "\n",
    "n = len(X_train1)\n",
    "k = len(X_train1.columns)\n",
    "for r in cvsvr_r2scores:\n",
    "    adj_r2 = 1-(((1-r)*(n-1))/(n-k-1))\n",
    "    cvsvr_adj.append(adj_r2)\n",
    "\n",
    "cvsvr_r2score = round((np.mean(cvsvr_r2scores)), 4)\n",
    "cvsvr_adjscore = round((np.mean(cvsvr_adj)), 4)\n",
    "cvsvr_rmsescore = (round(abs(np.mean(cvsvr_rmsescores)),2))\n",
    "cvsvr_maescore = (round(abs(np.mean(cvsvr_maescores)),2))\n",
    "\n",
    "print(cvsvr_r2score, cvsvr_adjscore, cvsvr_rmsescore, cvsvr_maescore)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "\n",
    "print(\"done training svr regressor | time taken: %f seconds\" %total)\n",
    "\n",
    "yPredsvr = svrRegressor.predict(X_test_scaled1)\n",
    "print('The average R2 value for SVR Regressor is :', cvsvr_r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: 6588 rows\n",
      "Size of testing dataset: 732 rows\n",
      "Done defining NEW variables\n"
     ]
    }
   ],
   "source": [
    "## defining variables WITH MULTICOLLINEARITY: random forest, decision tree, maybe adaboost, and xgboost\n",
    "\n",
    "X = df2[['PM10', 'NO', 'NO2', 'NOx', 'NH3','CO', 'SO2', 'O3', 'Toluene', 'Xylene', 'Temperature']]\n",
    "\n",
    "y = df2['O3P24']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0, test_size=0.1)\n",
    "\n",
    "print(\"Size of training dataset: {} rows\".format(X_train.shape[0]))\n",
    "print(\"Size of testing dataset: {} rows\".format(X_test.shape[0]))\n",
    "\n",
    "print('Done defining NEW variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING: rf\n",
      "[0.64832703 0.59362337 0.7117066  0.62370947 0.57214386 0.69173111\n",
      " 0.59662629 0.6339325  0.66129221 0.67005621]\n",
      "[-23.83398648 -27.51943475 -23.4018976  -25.0410992  -24.83850981\n",
      " -22.40640761 -27.95541033 -27.80335025 -24.51523794 -23.52545195]\n",
      "[-14.94503521 -15.70992004 -14.63032132 -15.06532281 -15.02689965\n",
      " -14.3236038  -15.3422457  -15.31698326 -15.04742006 -13.67048764]\n",
      "0.6403 0.6397 25.08 14.91\n",
      "0.6403 0.6397\n",
      "done training random forest regressor | time taken: 1073.418403 seconds\n",
      "The average R2 value for Random Forest Regressor is : 0.6403\n",
      "feature importances:::\n",
      "[ 7  1  3  4  2  8  6  0  5 10  9]\n"
     ]
    }
   ],
   "source": [
    "## random forest regressor\n",
    "print(\"STARTING: rf\")\n",
    "t0 = time.time()\n",
    "\n",
    "'''importing library'''\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "'''create regressor object'''\n",
    "rfRegressor = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=250) \n",
    "\n",
    "'''fitting regressor'''\n",
    "rfRegressor.fit(X_train, y_train)\n",
    "\n",
    "# cv stuff\n",
    "\n",
    "cvrf_r2scores = cross_val_score(rfRegressor, X_train, y_train, cv = 10, scoring = 'r2') # x_train was scaled for some reason, check if it changes things?\n",
    "print(cvrf_r2scores)\n",
    "cvrf_rmsescores = cross_val_score(rfRegressor, X_train, y_train, cv = 10, scoring = 'neg_root_mean_squared_error')\n",
    "print(cvrf_rmsescores)\n",
    "cvrf_maescores = cross_val_score(rfRegressor, X_train, y_train, cv = 10, scoring = 'neg_mean_absolute_error')\n",
    "print(cvrf_maescores)\n",
    "\n",
    "\n",
    "# calculating r^2 adj score\n",
    "\n",
    "cvrf_adj = []\n",
    "\n",
    "n = len(X_train)\n",
    "k = len(X_train.columns)\n",
    "for r in cvrf_r2scores:\n",
    "    adj_r2 = 1-(((1-r)*(n-1))/(n-k-1))\n",
    "    cvrf_adj.append(adj_r2)\n",
    "\n",
    "cvrf_r2score = round((np.mean(cvrf_r2scores)), 4)\n",
    "cvrf_adjscore = round((np.mean(cvrf_adj)), 4)\n",
    "cvrf_rmsescore = (round(abs(np.mean(cvrf_rmsescores)),2))\n",
    "cvrf_maescore = (round(abs(np.mean(cvrf_maescores)),2))\n",
    "\n",
    "print(cvrf_r2score, cvrf_adjscore, cvrf_rmsescore, cvrf_maescore)\n",
    "\n",
    "print(cvrf_r2score, cvrf_adjscore)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "\n",
    "print(\"done training random forest regressor | time taken: %f seconds\" %total)\n",
    "yPredrf = rfRegressor.predict(X_test)\n",
    "print('The average R2 value for Random Forest Regressor is :', cvrf_r2score)\n",
    "\n",
    "## printing feature importances\n",
    "\n",
    "importances = rfRegressor.feature_importances_\n",
    "\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print('feature importances:::')\n",
    "print(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING: dt\n",
      "[0.3890984  0.40715918 0.59598231 0.51715482 0.10130807 0.47768201\n",
      " 0.52179297 0.62493211 0.52275389 0.61343404]\n",
      "[-31.4132467  -33.23871281 -27.70345357 -28.36584314 -35.99830681\n",
      " -29.1658658  -30.43827626 -28.14307106 -29.10011599 -25.46418611]\n",
      "[-18.27096348 -19.1058252  -17.28815632 -17.33385933 -19.02967799\n",
      " -17.85336055 -17.46541274 -17.40754279 -17.57887826 -15.71521455]\n",
      "0.4771 0.4763 29.9 17.7\n",
      "done training decision tree regressor | time taken: 2.422012 seconds\n",
      "The average R2 value for Decision Tree Regressor is : 0.4771\n"
     ]
    }
   ],
   "source": [
    "## decision tree regressor\n",
    "print('STARTING: dt')\n",
    "t0 = time.time()\n",
    "\n",
    "'''importing library'''\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "'''create regressor object'''\n",
    "dtRegressor = DecisionTreeRegressor(random_state=0, max_depth = 6)\n",
    "\n",
    "'''fitting regressor'''\n",
    "dtRegressor.fit(X_train,y_train)\n",
    "\n",
    "# cv stuff\n",
    "\n",
    "cvdt_r2scores = cross_val_score(dtRegressor, X_train, y_train, cv = 10, scoring = 'r2')\n",
    "print(cvdt_r2scores)\n",
    "cvdt_rmsescores = cross_val_score(dtRegressor, X_train, y_train, cv = 10, scoring = 'neg_root_mean_squared_error')\n",
    "print(cvdt_rmsescores)\n",
    "cvdt_maescores = cross_val_score(dtRegressor, X_train, y_train, cv = 10, scoring = 'neg_mean_absolute_error')\n",
    "print(cvdt_maescores)\n",
    "\n",
    "\n",
    "# calculating r^2 adj score\n",
    "\n",
    "cvdt_adj = []\n",
    "\n",
    "n = len(X_train)\n",
    "k = len(X_train.columns)\n",
    "for r in cvdt_r2scores:\n",
    "    adj_r2 = 1-(((1-r)*(n-1))/(n-k-1))\n",
    "    cvdt_adj.append(adj_r2)\n",
    "\n",
    "cvdt_r2score = round((np.mean(cvdt_r2scores)), 4)\n",
    "cvdt_adjscore = round((np.mean(cvdt_adj)), 4)\n",
    "cvdt_rmsescore = (round(abs(np.mean(cvdt_rmsescores)),2))\n",
    "cvdt_maescore = (round(abs(np.mean(cvdt_maescores)),2))\n",
    "\n",
    "print(cvdt_r2score, cvdt_adjscore, cvdt_rmsescore, cvdt_maescore)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "\n",
    "print(\"done training decision tree regressor | time taken: %f seconds\" %total)\n",
    "\n",
    "yPreddt = dtRegressor.predict(X_test)\n",
    "print('The average R2 value for Decision Tree Regressor is :', cvdt_r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING: adaboost regressor\n",
      "[0.38352363 0.43645062 0.50216289 0.45578189 0.24155811 0.44554236\n",
      " 0.5189864  0.41503125 0.43343763 0.47300607]\n",
      "[-31.55625143 -32.40717226 -30.75228276 -30.11467905 -33.07027519\n",
      " -30.0497989  -30.52746577 -35.14656441 -31.70643287 -29.73177246]\n",
      "[-22.81522008 -23.3371048  -22.56439468 -23.12536314 -23.52035335\n",
      " -22.6473323  -20.75158973 -23.6598526  -23.0496313  -22.21528464]\n",
      "0.4305 0.4296 31.51 22.77\n",
      "done training Adaboost regressor | time taken: 95.046222 seconds\n",
      "The average R2 value for Adaboost Regressor is : 0.4305\n"
     ]
    }
   ],
   "source": [
    "## adaboost regressor\n",
    "print('STARTING: adaboost regressor')\n",
    "t0 = time.time()\n",
    "\n",
    "'''importing library'''\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "'''create regressor object'''\n",
    "adaRegressor = AdaBoostRegressor(random_state=0, learning_rate = 0.1, n_estimators=100)\n",
    "\n",
    "'''fitting regressor'''\n",
    "adaRegressor.fit(X_train, y_train)\n",
    "\n",
    "# cv stuff\n",
    "\n",
    "cvada_r2scores = cross_val_score(adaRegressor, X_train, y_train, cv = 10, scoring = 'r2')\n",
    "print(cvada_r2scores)\n",
    "cvada_rmsescores = cross_val_score(adaRegressor, X_train, y_train, cv = 10, scoring = 'neg_root_mean_squared_error')\n",
    "print(cvada_rmsescores)\n",
    "cvada_maescores = cross_val_score(adaRegressor, X_train, y_train, cv = 10, scoring = 'neg_mean_absolute_error')\n",
    "print(cvada_maescores)\n",
    "\n",
    "# calculating r^2 adj score\n",
    "\n",
    "cvada_adj = []\n",
    "\n",
    "n = len(X_train)\n",
    "k = len(X_train.columns)\n",
    "for r in cvada_r2scores:\n",
    "    adj_r2 = 1-(((1-r)*(n-1))/(n-k-1))\n",
    "    cvada_adj.append(adj_r2)\n",
    "\n",
    "cvada_r2score = round((np.mean(cvada_r2scores)), 4)\n",
    "cvada_adjscore = round((np.mean(cvada_adj)), 4)\n",
    "cvada_rmsescore = (round(abs(np.mean(cvada_rmsescores)),2))\n",
    "cvada_maescore = (round(abs(np.mean(cvada_maescores)),2))\n",
    "\n",
    "print(cvada_r2score, cvada_adjscore, cvada_rmsescore, cvada_maescore)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "\n",
    "print(\"done training Adaboost regressor | time taken: %f seconds\" %total)\n",
    "\n",
    "yPredada = adaRegressor.predict(X_test)\n",
    "print('The average R2 value for Adaboost Regressor is :', cvada_r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING: xgboost regressor\n",
      "[0.66385583 0.60605693 0.69213472 0.64184638 0.51992473 0.70113436\n",
      " 0.61715384 0.55477376 0.68405147 0.67579502]\n",
      "[-23.30182764 -27.09517007 -24.18321734 -24.43016618 -26.3106345\n",
      " -22.06202509 -27.23480218 -30.66245476 -23.67727337 -23.31996183]\n",
      "[-14.61349986 -15.55168113 -14.60653365 -14.61288832 -14.96284902\n",
      " -13.90012721 -14.86793313 -15.74012334 -14.38737653 -13.2580433 ]\n",
      "0.6357 0.6351 25.23 14.65\n",
      "done training xgboost regressor | time taken: 472.176263 seconds\n",
      "The average R2 value for xgboost Regressor is : 0.6357\n"
     ]
    }
   ],
   "source": [
    "## xgboost regressor\n",
    "print('STARTING: xgboost regressor')\n",
    "t0 = time.time()\n",
    "\n",
    "'''importing library'''\n",
    "import xgboost as xgb\n",
    "\n",
    "'''create regressor object'''\n",
    "xgbRegressor = xgb.XGBRegressor(learning_rate=0.1, max_depth=10, n_estimators=300, verbosity = 0, random_state = 0, silent = True)\n",
    "\n",
    "'''fitting regressor'''\n",
    "xgbRegressor.fit(X_train, y_train)\n",
    "\n",
    "# cv stuff\n",
    "\n",
    "cvxgb_r2scores = cross_val_score(xgbRegressor, X_train, y_train, cv = 10, scoring = 'r2')\n",
    "print(cvxgb_r2scores)\n",
    "cvxgb_rmsescores = cross_val_score(xgbRegressor, X_train, y_train, cv = 10, scoring = 'neg_root_mean_squared_error')\n",
    "print(cvxgb_rmsescores)\n",
    "cvxgb_maescores = cross_val_score(xgbRegressor, X_train, y_train, cv = 10, scoring = 'neg_mean_absolute_error')\n",
    "print(cvxgb_maescores)\n",
    "\n",
    "\n",
    "# calculating r^2 adj score\n",
    "\n",
    "cvxgb_adj = []\n",
    "\n",
    "n = len(X_train)\n",
    "k = len(X_train.columns)\n",
    "for r in cvxgb_r2scores:\n",
    "    adj_r2 = 1-(((1-r)*(n-1))/(n-k-1))\n",
    "    cvxgb_adj.append(adj_r2)\n",
    "\n",
    "cvxgb_r2score = round((np.mean(cvxgb_r2scores)), 4)\n",
    "cvxgb_adjscore = round((np.mean(cvxgb_adj)), 4)\n",
    "cvxgb_rmsescore = (round(abs(np.mean(cvxgb_rmsescores)),2))\n",
    "cvxgb_maescore = (round(abs(np.mean(cvxgb_maescores)),2))\n",
    "\n",
    "print(cvxgb_r2score, cvxgb_adjscore, cvxgb_rmsescore, cvxgb_maescore)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "\n",
    "print(\"done training xgboost regressor | time taken: %f seconds\" %total)\n",
    "\n",
    "yPredxgb = xgbRegressor.predict(X_test)\n",
    "print('The average R2 value for xgboost Regressor is :', cvxgb_r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 value for Linear Regression is         : 0.3847\n",
      "The R^2 value for KNN Regressor is             : 0.5889\n",
      "The R^2 value for SVM Regressor is             : 0.4427\n",
      "The R^2 value for Random Forests Regressor is  : 0.6403\n",
      "The R^2 value for Decision Tree Regressor is   : 0.4771\n",
      "The R^2 value for AdaBoost Regressor is        : 0.4305\n",
      "The R^2 value for XGBoost Regressor is         : 0.6357\n",
      "The Adj. R^2 value for Linear Regression is        : 0.3838\n",
      "The Adj. R^2 value for KNN Regressor is            : 0.5883\n",
      "The Adj. R^2 value for SVM Regressor is            : 0.4419\n",
      "The Adj. R^2 value for Random Forests Regressor is : 0.6397\n",
      "The Adj. R^2 value for Decision Tree Regressor is  : 0.4763\n",
      "The Adj. R^2 value for AdaBoost Regressor is       : 0.4296\n",
      "The Adj. R^2 value for XGBoost Regressor is        : 0.6351\n",
      "The RSME value for Linear Regression is         : 32.8\n",
      "The RSME value for KNN Regressor is             : 26.63\n",
      "The RSME value for SVM Regressor is             : 43.07\n",
      "The RSME value for Random Forests Regressor is  : 25.08\n",
      "The RSME value for Decision Tree Regressor is   : 29.9\n",
      "The RSME value for AdaBoost Regressor is        : 31.51\n",
      "The RSME value for XGBoost Regressor is         : 25.23\n",
      "The MAE value for Linear Regression is        : 20.6\n",
      "The MAE value for KNN Regressor is            : 15.7\n",
      "The MAE value for SVM Regressor is            : 30.84\n",
      "The MAE value for Random Forests Regressor is : 14.91\n",
      "The MAE value for Decision Tree Regressor is  : 17.7\n",
      "The MAE value for AdaBoost Regressor is       : 22.77\n",
      "The MAE value for XGBoost Regressor is        : 14.65\n"
     ]
    }
   ],
   "source": [
    "##### printing cross-validations scores\n",
    "# printing cross-validaion r^2 scores\n",
    "\n",
    "print('The R^2 value for Linear Regression is         :', cvln_r2score)\n",
    "print('The R^2 value for KNN Regressor is             :', cvkn_r2score)\n",
    "print('The R^2 value for SVM Regressor is             :', cvsvr_r2score)\n",
    "print('The R^2 value for Random Forests Regressor is  :', cvrf_r2score)\n",
    "print('The R^2 value for Decision Tree Regressor is   :', cvdt_r2score)\n",
    "print('The R^2 value for AdaBoost Regressor is        :', cvada_r2score)\n",
    "print('The R^2 value for XGBoost Regressor is         :', cvxgb_r2score)\n",
    "\n",
    "# printing cross-validation adjusted r^2 scores\n",
    "\n",
    "print('The Adj. R^2 value for Linear Regression is        :', cvln_adjscore)\n",
    "print('The Adj. R^2 value for KNN Regressor is            :', cvkn_adjscore)\n",
    "print('The Adj. R^2 value for SVM Regressor is            :', cvsvr_adjscore)\n",
    "print('The Adj. R^2 value for Random Forests Regressor is :', cvrf_adjscore)\n",
    "print('The Adj. R^2 value for Decision Tree Regressor is  :', cvdt_adjscore)\n",
    "print('The Adj. R^2 value for AdaBoost Regressor is       :', cvada_adjscore)\n",
    "print('The Adj. R^2 value for XGBoost Regressor is        :', cvxgb_adjscore)\n",
    "\n",
    "# printing cross-validation rmse scores\n",
    "\n",
    "print('The RSME value for Linear Regression is         :', cvln_rmsescore)\n",
    "print('The RSME value for KNN Regressor is             :', cvkn_rmsescore)\n",
    "print('The RSME value for SVM Regressor is             :', cvsvr_rmsescore)\n",
    "print('The RSME value for Random Forests Regressor is  :', cvrf_rmsescore)\n",
    "print('The RSME value for Decision Tree Regressor is   :', cvdt_rmsescore)\n",
    "print('The RSME value for AdaBoost Regressor is        :', cvada_rmsescore)\n",
    "print('The RSME value for XGBoost Regressor is         :', cvxgb_rmsescore)\n",
    "\n",
    "# printing cross-validation mae scores\n",
    "\n",
    "print('The MAE value for Linear Regression is        :', cvln_maescore)\n",
    "print('The MAE value for KNN Regressor is            :', cvkn_maescore)\n",
    "print('The MAE value for SVM Regressor is            :', cvsvr_maescore)\n",
    "print('The MAE value for Random Forests Regressor is :', cvrf_maescore)\n",
    "print('The MAE value for Decision Tree Regressor is  :', cvdt_maescore)\n",
    "print('The MAE value for AdaBoost Regressor is       :', cvada_maescore)\n",
    "print('The MAE value for XGBoost Regressor is        :', cvxgb_maescore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
